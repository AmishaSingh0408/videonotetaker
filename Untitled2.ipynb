{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0cRHl0mn7BXNCgOaPsxh8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmishaSingh0408/videonotetaker/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0r9DA9AkOIp"
      },
      "outputs": [],
      "source": [
        "!pip install -q yt-dlp openai-whisper transformers accelerate bitsandbytes\n",
        "\n",
        "print(\"All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def download_audio(video_url: str) -> str:\n",
        "    output_path = \"audio.mp3\"\n",
        "    print(f\" Downloading audio...\")\n",
        "\n",
        "    cmd = [\"yt-dlp\", \"-x\", \"--audio-format\", \"mp3\", \"-o\", output_path, video_url]\n",
        "    subprocess.run(cmd, check=True, capture_output=True)\n",
        "\n",
        "    print(f\" Downloaded!\\n\")\n",
        "    return output_path\n",
        "\n",
        "print(\" Downloader ready\")"
      ],
      "metadata": {
        "id": "XIPbBoAekwwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_path: str) -> dict:\n",
        "    print(f\" Transcribing...\")\n",
        "\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio_path, verbose=False)\n",
        "\n",
        "    print(f\" Transcribed {result['segments'][-1]['end']:.0f}s of audio\\n\")\n",
        "    return result\n",
        "\n",
        "print(\" Whisper ready\")"
      ],
      "metadata": {
        "id": "GOmaMPJ0lH4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "def format_timestamp(start: float, end: float) -> str:\n",
        "    def sec_to_time(sec):\n",
        "        m, s = divmod(int(sec), 60)\n",
        "        h, m = divmod(m, 60)\n",
        "        return f\"{h}:{m:02d}:{s:02d}\" if h else f\"{m}:{s:02d}\"\n",
        "    return f\"{sec_to_time(start)} - {sec_to_time(end)}\"\n",
        "\n",
        "def chunk_transcript(segments: List[Dict], chunk_duration: int = 180) -> List[Dict]:\n",
        "    \"\"\"Chunk into 3-minute segments (180s)\"\"\"\n",
        "    print(f\"  Chunking (every {chunk_duration}s)...\")\n",
        "\n",
        "    chunks = []\n",
        "    current = {\"text\": \"\", \"start\": 0, \"segments\": []}\n",
        "\n",
        "    for seg in segments:\n",
        "        if seg[\"end\"] - current[\"start\"] > chunk_duration and current[\"text\"]:\n",
        "            end_time = current[\"segments\"][-1][\"end\"]\n",
        "            chunks.append({\n",
        "                \"text\": current[\"text\"].strip(),\n",
        "                \"start\": current[\"start\"],\n",
        "                \"end\": end_time,\n",
        "                \"timestamp\": format_timestamp(current[\"start\"], end_time)\n",
        "            })\n",
        "            current = {\"text\": \"\", \"start\": seg[\"start\"], \"segments\": []}\n",
        "\n",
        "        current[\"text\"] += \" \" + seg[\"text\"]\n",
        "        current[\"segments\"].append(seg)\n",
        "        if not current[\"start\"]:\n",
        "            current[\"start\"] = seg[\"start\"]\n",
        "\n",
        "    if current[\"text\"]:\n",
        "        end_time = current[\"segments\"][-1][\"end\"]\n",
        "        chunks.append({\n",
        "            \"text\": current[\"text\"].strip(),\n",
        "            \"start\": current[\"start\"],\n",
        "            \"end\": end_time,\n",
        "            \"timestamp\": format_timestamp(current[\"start\"], end_time)\n",
        "        })\n",
        "\n",
        "    print(f\" Created {len(chunks)} chunks\\n\")\n",
        "    return chunks\n",
        "\n",
        "print(\" Chunker ready\")"
      ],
      "metadata": {
        "id": "FHlQv2CvlOlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  LOAD FREE LLM - Flan-T5 (No authentication needed)\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "print(\" Loading summarization model...\")\n",
        "\n",
        "model_name = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\" Model loaded!\\n\")\n",
        "\n",
        "\n",
        "def generate_summary(prompt: str) -> str:\n",
        "    \"\"\"Generate text using T5.\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=300,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "print(\" Generator ready\")"
      ],
      "metadata": {
        "id": "wxAnNK7lnGHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  GENERATE DETAILED NOTES WITH LLM\n",
        "\n",
        "\n",
        "def analyze_chunk(chunk_text: str, timestamp: str) -> Dict:\n",
        "    \"\"\"Analyze a chunk and extract structured notes.\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"Analyze this video transcript segment and create detailed study notes.\n",
        "\n",
        "Transcript ({timestamp}):\n",
        "{chunk_text}\n",
        "\n",
        "Create structured notes in this exact format:\n",
        "\n",
        "SUMMARY:\n",
        "[Write a 2-3 sentence summary of what this segment covers]\n",
        "\n",
        "KEY POINTS:\n",
        "- [First main point or concept]\n",
        "- [Second main point or concept]\n",
        "- [Third main point or concept]\n",
        "\n",
        "IMPORTANT FACTS:\n",
        "- [Any specific facts, numbers, dates, names mentioned]\n",
        "- [Another important fact]\n",
        "\n",
        "ACTION ITEMS:\n",
        "- [Any tasks, recommendations, or things to do]\n",
        "- [Or write \"None\" if there are no action items]\n",
        "\n",
        "Be specific and factual. Extract actual information from the transcript.\"\"\"\n",
        "\n",
        "    response = generate_summary(prompt, max_length=600)\n",
        "\n",
        "\n",
        "    result = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"summary\": \"\",\n",
        "        \"key_points\": [],\n",
        "        \"important_facts\": [],\n",
        "        \"action_items\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    import re\n",
        "\n",
        "    summary_match = re.search(r'SUMMARY:\\s*(.+?)(?=KEY POINTS:|IMPORTANT FACTS:|ACTION ITEMS:|$)', response, re.DOTALL)\n",
        "    if summary_match:\n",
        "        result[\"summary\"] = summary_match.group(1).strip()\n",
        "\n",
        "    key_match = re.search(r'KEY POINTS:\\s*(.+?)(?=IMPORTANT FACTS:|ACTION ITEMS:|$)', response, re.DOTALL)\n",
        "    if key_match:\n",
        "        points = [p.strip('- ').strip() for p in key_match.group(1).split('\\n') if p.strip().startswith('-')]\n",
        "        result[\"key_points\"] = points\n",
        "\n",
        "    facts_match = re.search(r'IMPORTANT FACTS:\\s*(.+?)(?=ACTION ITEMS:|$)', response, re.DOTALL)\n",
        "    if facts_match:\n",
        "        facts = [f.strip('- ').strip() for f in facts_match.group(1).split('\\n') if f.strip().startswith('-')]\n",
        "        result[\"important_facts\"] = facts\n",
        "\n",
        "    action_match = re.search(r'ACTION ITEMS:\\s*(.+?)$', response, re.DOTALL)\n",
        "    if action_match:\n",
        "        actions = [a.strip('- ').strip() for a in action_match.group(1).split('\\n') if a.strip().startswith('-')]\n",
        "        result[\"action_items\"] = actions\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def process_all_chunks(chunks: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"Process all chunks with LLM.\"\"\"\n",
        "    print(f\"Generating detailed notes for {len(chunks)} chunks...\")\n",
        "    print(\"   (This will take a few minutes)\\n\")\n",
        "\n",
        "    results = []\n",
        "    for i, chunk in enumerate(chunks, 1):\n",
        "        print(f\"   [{i}/{len(chunks)}] Processing {chunk['timestamp']}...\")\n",
        "        result = analyze_chunk(chunk[\"text\"], chunk[\"timestamp\"])\n",
        "        results.append(result)\n",
        "\n",
        "    print(f\"\\n All chunks analyzed!\\n\")\n",
        "    return results\n",
        "\n",
        "print(\" Analyzer ready\")"
      ],
      "metadata": {
        "id": "BL4fc82WoCxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  GENERATE DETAILED MARKDOWN NOTES\n",
        "\n",
        "\n",
        "def generate_detailed_notes(results: List[Dict], video_url: str, full_transcript: str) -> str:\n",
        "    \"\"\"Generate comprehensive markdown notes.\"\"\"\n",
        "\n",
        "    notes = f\"#  Video Study Notes\\n\\n\"\n",
        "    notes += f\"**Source:** {video_url}\\n\\n\"\n",
        "    notes += f\"---\\n\\n\"\n",
        "\n",
        "\n",
        "    notes += \"##  Executive Summary\\n\\n\"\n",
        "    all_summaries = [r[\"summary\"] for r in results if r[\"summary\"]]\n",
        "    if all_summaries:\n",
        "        notes += \" \".join(all_summaries[:3])\n",
        "    notes += \"\\n\\n---\\n\\n\"\n",
        "\n",
        "\n",
        "    notes += \"##  Action Items\\n\\n\"\n",
        "    all_actions = []\n",
        "    for r in results:\n",
        "        for action in r[\"action_items\"]:\n",
        "            if action.lower() not in [\"none\", \"no action items\"]:\n",
        "                all_actions.append(f\"- **[{r['timestamp']}]** {action}\")\n",
        "\n",
        "    if all_actions:\n",
        "        notes += \"\\n\".join(all_actions)\n",
        "    else:\n",
        "        notes += \"*No specific action items mentioned*\"\n",
        "\n",
        "    notes += \"\\n\\n---\\n\\n\"\n",
        "\n",
        "\n",
        "    notes += \"##  Detailed Notes by Timestamp\\n\\n\"\n",
        "\n",
        "    for r in results:\n",
        "        notes += f\"###  {r['timestamp']}\\n\\n\"\n",
        "\n",
        "        if r[\"summary\"]:\n",
        "            notes += f\"**Overview:** {r['summary']}\\n\\n\"\n",
        "\n",
        "        if r[\"key_points\"]:\n",
        "            notes += f\"**Key Concepts:**\\n\"\n",
        "            for point in r[\"key_points\"]:\n",
        "                notes += f\"- {point}\\n\"\n",
        "            notes += \"\\n\"\n",
        "\n",
        "        if r[\"important_facts\"]:\n",
        "            notes += f\"**Important Details:**\\n\"\n",
        "            for fact in r[\"important_facts\"]:\n",
        "                notes += f\"- {fact}\\n\"\n",
        "            notes += \"\\n\"\n",
        "\n",
        "        notes += \"---\\n\\n\"\n",
        "\n",
        "\n",
        "    notes += \"##  Full Transcript\\n\\n\"\n",
        "    notes += f\"```\\n{full_transcript}\\n```\\n\"\n",
        "\n",
        "    return notes\n",
        "\n",
        "print(\" Note generator ready\")"
      ],
      "metadata": {
        "id": "QHpzWMiooboo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  RUN THE FULL PIPELINE\n",
        "\n",
        "\n",
        "def process_video(video_url: str):\n",
        "    print(\"=\"*60)\n",
        "    print(\" DETAILED VIDEO NOTE TAKER\")\n",
        "    print(\"=\"*60)\n",
        "    print()\n",
        "\n",
        "\n",
        "    audio_path = download_audio(video_url)\n",
        "\n",
        "\n",
        "    transcript = transcribe_audio(audio_path)\n",
        "    full_text = transcript[\"text\"]\n",
        "\n",
        "\n",
        "    chunks = chunk_transcript(transcript[\"segments\"], chunk_duration=180)\n",
        "\n",
        "\n",
        "    results = process_all_chunks(chunks)\n",
        "\n",
        "\n",
        "    notes = generate_detailed_notes(results, video_url, full_text)\n",
        "\n",
        "\n",
        "    with open(\"detailed_notes.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(notes)\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\" COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\n Preview:\\n\")\n",
        "    print(notes[:2000])\n",
        "\n",
        "    from google.colab import files\n",
        "    files.download(\"detailed_notes.md\")\n",
        "\n",
        "    return notes\n",
        "\n",
        "print(\" Pipeline ready!\")"
      ],
      "metadata": {
        "id": "coLJ-B6Zo_EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_url = input(\"Enter YouTube URL: \").strip()\n",
        "notes = process_video(video_url)"
      ],
      "metadata": {
        "id": "miZYx89vpT5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}